# Motion Detector and Tracker using Python

# Problem statement:
# Motion detection and tracking system:

# 1. create a tracker based on motion in python.
# 2. It should be able to detect motion from your webcam and then also track each object motion simultaneously, keeping track of each object.
# 3. You have to implement preprocessing and post processing on your input image to improve the results.
# 4. You then need to show input image, preprocessed image, post processed motion mask and final image with object tracking.


# importing OpenCV, time, Numpy and Pandas library

import cv2
import time 
import pandas as pd
import numpy as np

# importing datetime class from datetime library
from datetime import datetime as dt

# Assigning our static_back to None
static_back = None

# List when any moving object appear
motion_list = [ None, None ]

# Create the background subtractor object and Use the last 700 video frames to build the background
object_detector = cv2.createBackgroundSubtractorMOG2(history=700, varThreshold=40)

# Time of movement
time = []

# Initializing DataFrame, one column is start_of_time
# and other column is end_of_time
df = pd.DataFrame(columns = ["Start_of_time", "End_of_time"])

# Capturing video
cap = cv2.VideoCapture(0)

# Create kernel for morphological operation
# You can tweak the dimensions of the kernel
kernel = np.ones((25, 25), np.uint8)


# Infinite while loop to treat stack of image as video
while True:
	# Reading frame(image) from video
	check, frame = cap.read()
	
        # showing input frame
	cv2.imshow("original_frame",frame)
	
	# applying on each frame and showing the masked image
        fgmask = object_detector.apply(frame)
	
	# Close dark gaps in foreground object using closing
        fg_mask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)
	
	# Remove salt and pepper noise with a median filter
        fg_mask = cv2.medianBlur(fg_mask, 5)
	
	# Displaying the masked frame
        cv2.imshow('mask frame', fgmask)
	
	# Initializing motion = 0(no motion)
	motion = 0

	# Converting color image to gray_scale image
	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

	# Converting gray scale image to GaussianBlur
	# so that change can be find easily
	gray = cv2.GaussianBlur(gray, (21, 21), 0)

	# In first iteration we assign the value of static_back to our first frame
	
	if static_back is None:
		static_back = gray
		continue

	# Difference between static background and current frame(which is GaussianBlur)
	
	diff_frame = cv2.absdiff(static_back, gray)

	# If change in between static background and
	# current frame is greater than 40 it will show white color(255)
	thresh_frame = cv2.threshold(diff_frame, 40, 255, cv2.THRESH_BINARY)[1]
	thresh_frame = cv2.dilate(thresh_frame, None, iterations = 5)

	# Finding contour of moving object
	cnts,_ = cv2.findContours(thresh_frame.copy(),
					cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

	for contour in cnts:
		if cv2.contourArea(contour) < 10000:
			continue
		motion = 1

		(x, y, w, h) = cv2.boundingRect(contour)
		# making green rectangle around the moving object
		cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)
		
		# Draw circle in the center of the bounding box
                x2 = x + int(w / 2)
                y2 = y + int(h / 2)
                cv2.circle(frame, (x2, y2), 4, (0, 255, 0), -1)
		
		# Print the centroid coordinates (we'll use the center of the bounding box) on the image
                text = "x: " + str(x2) + ", y: " + str(y2)
                cv2.putText(frame, text, (x2 - 10, y2 - 10),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

	# Appending status of motion
	motion_list.append(motion)

	motion_list = motion_list[-2:]

	# Appending Start time of motion
	if motion_list[-1] == 1 and motion_list[-2] == 0:
		time.append(dt.now())

	# Appending End time of motion
	if motion_list[-1] == 0 and motion_list[-2] == 1:
		time.append(dt.now())

	# Displaying image in gray_scale
	cv2.imshow("Gray Frame", gray)

	# Displaying the difference in currentframe to the staticframe(very first_frame)
	
	cv2.imshow("Difference Frame", diff_frame)

	# Displaying the black and white image in which if intensity difference greater than 30 it will appear white
	
	cv2.imshow("Threshold Frame", thresh_frame)

	# Displaying color frame with contour of motion of object
	cv2.imshow("Color Frame", frame)

	key = cv2.waitKey(1)
	
	# if q entered whole process will stop
	if key == ord('q'):
		# if something is movingthen it append the end time of movement
		if motion == 1:
			time.append(dt.now())
		break

# Appending time of motion in DataFrame
for i in range(0, len(time), 2):
	df = df.append({"Start_of_time":time[i], "End_of_time":time[i + 1]}, ignore_index = True)

# Creating a CSV file in which time of movements will be saved
df.to_csv("Time_of_movements.csv")

cap.release()

# Destroying all the windows
cv2.destroyAllWindows()

